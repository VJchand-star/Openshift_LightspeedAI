#######################################
## GLOBAL SETTINGS
#######################################
## enabe OLS UI
OLS_ENABLE_UI=True
## LLMs backends {'ollama','tgi','openai','bam','watson'}
LLM_DEFAULT=openai
 
# logging config
# Logs to stdout if not set 
# LOG_FILE_NAME=/tmp/ols.log

# Default is ~100 megs
# LOG_FILE_SIZE = <size in bytes>

LOG_LEVEL=INFO
LOG_LEVEL_CONSOLE=INFO

OLS_CONVERSATION_CACHE=in-memory


#######################################
## LLM BACKENDS
#######################################
## BAM
BAM_API_KEY=<api_key>
BAM_API_URL=https://bam-api.res.ibm.com

## Open AI
OPENAI_API_KEY=<api_key>

# set these if you want to use non-default models for different functions
# BASE_COMPLETION_MODEL=
# HAPPY_RESPONSE_GENERATOR_MODEL=
# QUESTION_VALIDATOR_MODEL=
# TASK_BREAKDOWN_MODEL=
# TASK_PERFORMER_MODEL=
# TASK_PROCESSOR_MODEL=
# REPHRASE_MODEL=
# YAML_MODEL=
# YESNO_MODEL=
# DOC_SUMMARIZER_MODEL=
# INDEXER_MODEL=